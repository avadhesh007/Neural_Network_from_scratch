{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 align=\"right\">by <a href=\"http://cse.iitkgp.ac.in/~adas/\">Abir Das</a> with help of <br> Ram Rakesh and Ankit Singh<br> </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the following details here\n",
    "** Name: ** `<Avadhesh Kumar Verma>`<br/>\n",
    "** Roll Number: ** `<15CH30034>`<br/>\n",
    "** Department: ** `<Chemical Engineering>`<br/>\n",
    "** Email: ** `<ak1000vema@gmail.com>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "To run and solve this assignment, one must have a working IPython Notebook installation. The easiest way to set it up for both Windows and Linux is to install [Anaconda](https://www.continuum.io/downloads). Then save this file ([`assignment_01.ipynb`]()) to your computer, run Anaconda and choose this file in Anaconda's file explorer. Use `Python 3` version. Below statements assume that you have already followed these instructions. If you are new to Python or its scientific library, Numpy, there are some nice tutorials [here](https://www.learnpython.org/) and [here](http://www.scipy-lectures.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: You will implement a fully connected neural network from scratch in this problem\n",
    "We marked places where you are expected to add/change your own code with **`##### write your code below #####`** comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "597wDiAvGvuB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are not supposed to import any other python library to work on this assignments.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "'''You are not supposed to import any other python library to work on this assignments.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "B54oZmm1DNWe",
    "outputId": "8c59bd48-230d-4fb9-eba1-82471de363df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 60000\n"
     ]
    }
   ],
   "source": [
    "'''data is loaded from data directory.\n",
    "please don't remove the folder '''\n",
    "\n",
    "x_train = np.load('./data/X_train.npy')\n",
    "x_train = x_train.flatten().reshape(-1,28*28)\n",
    "x_train = x_train / 255.0\n",
    "gt_indices = np.load('./data/y_train.npy')\n",
    "train_length = len(x_train)\n",
    "print(\"Number of training examples: {:d}\".format(train_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvVFhXNB5xrD"
   },
   "outputs": [],
   "source": [
    "'''Dimensions to be used for creating your model'''\n",
    "\n",
    "batch_size = 64  # batch size\n",
    "input_dim = 784  # input dimension\n",
    "hidden_1_dim = 512  # hidden layer 1 dimension\n",
    "hidden_2_dim = 256  # hidden layer 2 dimension\n",
    "output_dim = 10   # output dimension\n",
    "\n",
    "'''Other hyperparameters'''\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hImaaujc5zXg"
   },
   "outputs": [],
   "source": [
    "#creating one hot vector representation of output classification\n",
    "y_train = np.zeros((train_length, output_dim))\n",
    "# print(y.shape, gt_indices.shape)\n",
    "for i in range(train_length):\n",
    "    y_train[i,gt_indices[i]] = 1\n",
    "\n",
    "# Number of mini-batches (as integer) in one epoch\n",
    "num_minibatches = np.floor(train_length/batch_size).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W7lHWEWVaVlK",
    "outputId": "4ecb1bfc-4568-44cb-e109-57677da50eb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of mini-batches 937 and total training data used in training:59968.\n"
     ]
    }
   ],
   "source": [
    "print(\"No of mini-batches {:d} and total training data used in training:\\\n",
    "{}.\".format(num_minibatches, num_minibatches*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9HRf0Wj52cK"
   },
   "outputs": [],
   "source": [
    "'''Randomly Initialize Weights  from standard normal distribution (i.e., mean = 0 and s.d. = 1.0).\n",
    "Use the dimesnions specified in the cell 3 to initialize your weights matrices. \n",
    "Use the nomenclature W1,W2 etc. (provided below) for the different weight matrices.'''\n",
    "\n",
    "########################## write your code below ##############################################\n",
    "W1 = np.random.randn(input_dim,hidden_1_dim)\n",
    "W2 = np.random.randn(hidden_1_dim,hidden_2_dim)\n",
    "W3 = np.random.randn(hidden_2_dim,output_dim)\n",
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmZRrEVb6CJy"
   },
   "outputs": [],
   "source": [
    "# Write a function which computes the softmax where X is vector of scores computed during forward pass\n",
    "def softmax(x):\n",
    "    ##############################write your code here #################################\n",
    "    return np.exp(x)/(np.sum(np.exp(x), axis = 1)[:, np.newaxis])\n",
    "    ####################################################################################\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu(x):\n",
    "    return np.maximum(x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "Gjz4yhwE6JQw",
    "outputId": "341578db-29a4-48ca-b0f8-a0343aadd24b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0, iteration: 0, Loss: 2.6451 \n",
      " Epoch: 1, iteration: 937, Loss: 2.0231 \n",
      " Epoch: 2, iteration: 1874, Loss: 1.6814 \n",
      " Epoch: 3, iteration: 2811, Loss: 1.4781 \n",
      " Epoch: 4, iteration: 3748, Loss: 1.3511 \n",
      " Epoch: 5, iteration: 4685, Loss: 1.2660 \n",
      " Epoch: 6, iteration: 5622, Loss: 1.2066 \n",
      " Epoch: 7, iteration: 6559, Loss: 1.1632 \n",
      " Epoch: 8, iteration: 7496, Loss: 1.1309 \n",
      " Epoch: 9, iteration: 8433, Loss: 1.1060 \n",
      " Epoch: 10, iteration: 9370, Loss: 1.1036 \n",
      " Epoch: 11, iteration: 10307, Loss: 1.1014 \n",
      " Epoch: 12, iteration: 11244, Loss: 1.0992 \n",
      " Epoch: 13, iteration: 12181, Loss: 1.0971 \n",
      " Epoch: 14, iteration: 13118, Loss: 1.0951 \n",
      " Epoch: 15, iteration: 14055, Loss: 1.0931 \n",
      " Epoch: 16, iteration: 14992, Loss: 1.0911 \n",
      " Epoch: 17, iteration: 15929, Loss: 1.0892 \n",
      " Epoch: 18, iteration: 16866, Loss: 1.0874 \n",
      " Epoch: 19, iteration: 17803, Loss: 1.0856 \n",
      " Epoch: 20, iteration: 18740, Loss: 1.0854 \n",
      " Epoch: 21, iteration: 19677, Loss: 1.0852 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_of_iterations = 20000\n",
    "loss_list=[]\n",
    "i_epoch = 0\n",
    "for i_iter in range(no_of_iterations):\n",
    "    \n",
    "    ''''''\n",
    "    batch_elem_idx = i_iter%num_minibatches\n",
    "    x_batchinput = x_train[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size]\n",
    "    \n",
    "    ########################## write your code below ##############################################\n",
    "    ######################### Forward Pass Block #####################################\n",
    "    '''Write the code for forward block of the neural network with 2 hidden layers.\n",
    "    Please stick to the notation below which follows the notation provided in the lecture slides.\n",
    "    Note that you are allowed to write the right hand sides of these variables in more than\n",
    "    one line if that is convenient for you.'''\n",
    "    \n",
    "    # first hidden layer implementation\n",
    "    a1 = np.matmul(x_batchinput,W1)\n",
    "    # implement Relu layer\n",
    "    h1 =  Relu(a1)\n",
    "    \n",
    "    #  implement 2 hidden layer\n",
    "    a2 = np.dot(h1,W2)\n",
    "    # implement Relu activation \n",
    "    h2 = Relu(a2)\n",
    "    #implement linear output layer\n",
    "    a3 = np.dot(h2,W3)\n",
    "    a3= (a3 - np.mean(a3))/((np.var(a3) + 0.00000001)**(0.5))\n",
    "    # softmax layer\n",
    "    softmax_score = softmax(a3) #enusre you have implemented the softmax function defined above\n",
    "    ##################################################################################\n",
    "    ###############################################################################################\n",
    "\n",
    "    neg_log_softmax_score = -np.log(softmax_score+0.00000001) # The small number is added to avoid 0 input to log function\n",
    "    \n",
    "    # Compute and print loss\n",
    "    if i_iter%num_minibatches == 0:\n",
    "        loss = np.mean(np.diag(np.take(neg_log_softmax_score, gt_indices[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size],\\\n",
    "                                       axis=1)))\n",
    "        print(\" Epoch: {:d}, iteration: {:d}, Loss: {:6.4f} \".format(i_epoch, i_iter, loss))\n",
    "        loss_list.append(loss)\n",
    "        i_epoch += 1\n",
    "        # Each 10th epoch reduce learning rate by a factor of 10\n",
    "        if i_epoch%10 == 0:\n",
    "            learning_rate /= 10.0\n",
    "     \n",
    "    ################################### Backpropagation Code Block #####################################\n",
    "    ''' Use the convention grad_{} for computing the gradients.\n",
    "    for e.g \n",
    "        grad_W1 for gradients w.r.t. weight W1\n",
    "        grad_w2 for gradients w.r.t. weights W2'''\n",
    "    ########################## write your code below ##############################################\n",
    "    # Gradient of cross-entropy loss w.r.t. preactivation of the output layer\n",
    "    grad_softmax_score = -(y_train[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size]-softmax_score)\n",
    "    \n",
    "    # gradient w.r.t W3\n",
    "    grad_W3 = np.dot(np.transpose(h2),grad_softmax_score)/batch_size\n",
    "    # gradient w.r.t h2\n",
    "    grad_h2 = np.matmul(grad_softmax_score,W3.T)\n",
    "    # gradient w.r.t a2\n",
    "    grad_a2 = (grad_h2 *np.where(a2>0,1.0,0))\n",
    "    # gradient w.r.t W2\n",
    "    grad_W2 = np.dot(np.transpose(h1),grad_a2)/batch_size\n",
    "    # gradient w.r.t h1\n",
    "    grad_h1 = np.matmul(grad_a2,W2.T)\n",
    "    # gradient w.r.t a1\n",
    "    grad_a1 = (grad_h1*np.where(a1>0,1.0,0))\n",
    "    # gradient w.r.t W1\n",
    "    grad_W1 = np.dot(x_batchinput.T,grad_a1)/batch_size\n",
    "    ###############################################################################################\n",
    "    ####################################################################################################\n",
    "    \n",
    "    \n",
    "    ################################ Update Weights Block using SGD ####################################\n",
    "    W3 -= learning_rate * grad_W3\n",
    "    W2 -= learning_rate * grad_W2\n",
    "    W1 -= learning_rate * grad_W1\n",
    "    ####################################################################################################\n",
    "    \n",
    "#plotting the loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(loss_list)\n",
    "plt.title('Loss vs epochs')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading the test data from data/X_test.npy and data/y_test.npy.'''\n",
    "x_test = np.load('./data/X_test.npy')\n",
    "x_test = x_test.flatten().reshape(-1,28*28)\n",
    "x_test = x_test / 255.0\n",
    "y_test = np.load('./data/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 43.12 %\n"
     ]
    }
   ],
   "source": [
    "batch_size_test = 100 # Deliberately taken 100 so that it divides the test data size\n",
    "num_minibatches = len(y_test)/batch_size_test\n",
    "test_correct = 0\n",
    "\n",
    "'''Only forward block code and compute softmax_score .'''\n",
    "for i_iter in range(int(num_minibatches)):\n",
    "    \n",
    "    '''Get one minibatch'''\n",
    "    batch_elem_idx = i_iter%num_minibatches\n",
    "    x_batchinput = x_test[i_iter*batch_size_test:(i_iter+1)*batch_size_test]\n",
    "    \n",
    "    ######### copy only the forward pass block of your code and pass the x_batchinput to it and compute softmax_score ##########\n",
    "    # first hidden layer implementation\n",
    "    a1 = np.dot(x_batchinput,W1)\n",
    "    # implement Relu layer\n",
    "    h1 = Relu(a1)\n",
    "    #  implement 2 hidden layer\n",
    "    a2 = np.matmul(h1,W2)\n",
    "    # implement Relu activation \n",
    "    h2 = Relu(a2)\n",
    "    #implement linear output layer\n",
    "    a3 = np.matmul(h2,W3)\n",
    "    # softmax layer\n",
    "    softmax_score = softmax(a3) #enusre you have implemented the softmax function defined above\n",
    "    ##################################################################################\n",
    "    \n",
    "    y_batchinput = y_test[i_iter*batch_size_test:(i_iter+1)*batch_size_test]\n",
    "    \n",
    "    y_pred = np.argmax(softmax_score, axis=1)\n",
    "    num_correct_i_iter = np.sum(y_pred == y_batchinput)\n",
    "    test_correct += num_correct_i_iter\n",
    "print (\"Test accuracy is {:4.2f} %\".format(test_correct/len(y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_Hidden_MLP_New.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
